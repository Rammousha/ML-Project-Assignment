---
output: pdf_document
---

#  Machine Learning Project

##  Project Introduction

**Summary**  
  
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively.  In this project, our goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and try to predict the manner in which they did the exercise. This is the “classe” variable in the training set. We will compare the accuracy of the models and choose the best model to apply on the given test set; the obtained results will be chosen as answers to the multiple choice quiz.
 
**Data**  
  

The training data for this project are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv  
The test data are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv  

  
```{r, warning=F, message=F}
#set library path
.libPaths("D:/R/R-3.5.0/library")

#Load Packages
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
```


##  Load the training and testing data.
```{r}


#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))

rm(pml_training_url,pml_testing_url)


```


##  Split the pml_training data into train data & test data; our outcome is the "classe" variable.
**pml_training:** we will allocate 60% of  to be our training data and the rest; 40% to be our test data
**pml_testing:** we will apply our selected best prediction model on this data and obtain the results we need to insert later in the multiple choice quiz.

```{r }

inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and
#40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]

dim(my_training); 
dim(my_testing)

rm(inTrain)

```


##  Cleaning data

```{r }

# Remove the extra first column; equivalent to row names.
my_training <- my_training[c(-1)]


#Remove predictors that have one unique value (i.e: zero variance predictors) or those that
#satisfy the following: 
#1. Very few unique values relative to the number of samples  
#2. Ratio of the frequency of the most common value to the frequency of the second most 
#common value is large
nzv <- nearZeroVar(my_training, saveMetrics=TRUE)
my_training <- my_training[,nzv$nzv==FALSE]


nzv<- nearZeroVar(my_testing,saveMetrics=TRUE)
my_testing <- my_testing[,nzv$nzv==FALSE]



# Clean variables with more than 70% NA
index_to_rm <- NULL
for (i in 1:ncol(my_training))
{
if  ( length(which(is.na(my_training[,i])==T)) / nrow(my_training) >= 0.7 )
index_to_rm <- append(index_to_rm, i)
}

my_training <- my_training[,-index_to_rm]
  
rm(i, index_to_rm,nzv)




# Specify which columns to include in each of pml_testing & my_testing data frames for consistency with 
#my_training.


# we will use classe variable to build the confusion matrix (together with our prediction)
columns_to_include_in_mytesting <- colnames(my_training)

# since the classe variable doesn't exist in pml_testing
columns_to_include_in_pmltesting <- colnames(my_training[, -58]) 

# allow only variables in mytesting that are also in mytraining (this includes classe variable)
my_testing <- my_testing[columns_to_include_in_mytesting] 

 # allow only variables in pml_testing that are also in mytraining (this doesn't include classe variable)
pml_testing <- pml_testing[columns_to_include_in_pmltesting]


rm(columns_to_include_in_mytesting,columns_to_include_in_pmltesting)


```

```{r }

#  print the dimensions of my_testing and pml_testing
dim(my_testing)
dim(pml_testing)


```



```{r }

#  Unifying data structures between my_training, my_testing and pml_testing by converting all 
#integer variable types into numerics (for the commonly existing columns)



# To get the same class between testing and mytraining
my_testing <- rbind(my_training[2, ] , my_testing)
my_testing <- my_testing[-1,]



# To get the same class between testing and mytraining
pml_testing <- rbind(my_training[2, -58] , pml_testing)
pml_testing <- pml_testing[-1,]

```


##  Prediction
We will experiment with 3 prediction models and choose the one that gives us the highest accuracy and apply it on plm_testing in order to obtain our results for the quiz section.

###  Decision Trees
```{r }

set.seed(1)
model_1<- train(classe ~ ., data=my_training, method="rpart") #use all variables to predict the 
#classe outcome.
fancyRpartPlot(model_1$finalModel)

```

In order to test accuracy apply the model on the test set: my_testing

```{r}

predictions1 <- predict(model_1, my_testing) #apply model on my_testing

#insepect accuracy and other statistics via confusionMatrix by 
#comparing with the original my_testing data
cmtree <- confusionMatrix(predictions1, my_testing$classe)
cmtree
```
```{r }

plot(cmtree$table, col = cmtree$byClass, main = paste("Decision Tree: Accuracy =", 
                                                round(cmtree$overall['Accuracy'], 4)))

```


###  Random Forests

```{r }

set.seed(1)

model_2 <- randomForest(classe ~ ., data=my_training)
prediction2 <- predict(model_2, my_testing, type = "class")
cmrf <- confusionMatrix(prediction2, my_testing$classe)
cmrf
```

```{r }

plot(model_2)
```


```{r }

plot(cmrf$table, col = cmtree$byClass, main = paste("Random Forest: Accuracy =", round(cmrf$overall['Accuracy'], 4)))

```




###  Boosting with Trees

```{r }

set.seed(1)


fitControl <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 1)

model_3 <- train(classe ~ ., data=my_training, method = "gbm",
                 trControl = fitControl,
                 verbose = FALSE)



prediction3 <- predict(model_3, newdata=my_testing)
cmGBM <- confusionMatrix(prediction3, my_testing$classe)
cmGBM

```

```{r }

plot(model_3, ylim=c(0.9, 1))

```


##  Selecting the best model to apply on the Test Data


By comparing the accuracy among the 3 models, we notice that the Random Forests model gave us the highest accuracy 99.81%; thus the expected out-of-sample error is 100-99.81 = 0.19%. We choose RF to apply on the test data: plm_testing. The obtained results are the ones to be selected as answers to the multiple choice quiz.
```{r }

prediction_model_2 <- predict(model_2, pml_testing, type = "class")
prediction_model_2

```


