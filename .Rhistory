#set library path
.libPaths("D:/R/R-3.5.0/library")
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
.libPaths("D:/R/R-3.5.0/library")
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training); dim(my_testing)
rm(inTrain)
my_training <- my_training[c(-1)]
nzv <- nearZeroVar(my_training, saveMetrics=TRUE)
my_training <- my_training[,nzv$nzv==FALSE]
nzv<- nearZeroVar(my_testing,saveMetrics=TRUE)
my_testing <- my_testing[,nzv$nzv==FALSE]
rm(nzv)
index_to_rm <- NULL
for (i in 1:ncol(my_training))
{
if  ( length(which(is.na(my_training[,i])==T)) / nrow(my_training) >= 0.7 )
index_to_rm <- append(index_to_rm, i)
}
my_training <- my_training[,-index_to_rm]
rm(i, index_to_rm)
clean1 <- colnames(my_training)
clean2 <- colnames(my_training[, -58])  # remove the classe column
my_testing <- my_testing[clean1]         # allow only variables in mytesting that are also in mytraining (this includes classe variable)
pml_testing <- pml_testing[clean2]     # allow only variables in pml_testing that are also in mytraining (this doesn't include classe variable)
dim(my_testing)
rm(clean1,clean2)
pml_testing[,c(5:length(pml_testing))] <- apply(pml_testing[,c(5:length(pml_testing))], 2, function(x) as.numeric(x))
my_training[,c(5:(length(my_training)-1))] <- apply(my_training[,c(5:(length(my_training)-1))], 2, function(x) as.numeric(x))
my_testing[,c(5:(length(my_testing)-1))] <- apply(my_testing[,c(5:(length(my_testing)-1))], 2, function(x) as.numeric(x))
set.seed(12345)
modFitA1 <- rpart(classe ~ ., data=my_training, method="class")
fancyRpartPlot(modFitA1)
predictionsA1 <- predict(modFitA1, my_testing, type = "class") #apply model on my_testing
cmtree <- confusionMatrix(predictionsA1, my_testing$classe)    #insepect accuracy and other statistics via confusionMatrix by comparing with the original my_testing data
cmtree
plot(cmtree$table, col = cmtree$byClass, main = paste("Decision Tree Confusion Matrix: Accuracy =", round(cmtree$overall['Accuracy'], 3)))
set.seed(12345)
modFitB1 <- randomForest(classe ~ ., data=my_training)
predictionB1 <- predict(modFitB1, my_testing, type = "class")
cmrf <- confusionMatrix(predictionB1, my_testing$classe)
cmrf
plot(cmrf$table, col = cmtree$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 3)))
set.seed(12345)
fitControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 1)
gbmFit1 <- train(classe ~ ., data=my_training, method = "gbm",
trControl = fitControl,
verbose = FALSE)
gbmFinMod1 <- gbmFit1$finalModel
gbmPredTest <- predict(gbmFit1, newdata=my_testing)
gbmAccuracyTest <- confusionMatrix(gbmPredTest, my_testing$classe)
gbmAccuracyTest
plot(gbmFit1, ylim=c(0.9, 1))
predictionB2 <- predict(modFitB1, testing, type = "class")
predictionB2 <- predict(modFitB1, pml_testing, type = "class")
colnames(pml_testing)==colnames(my_training)
str(pml_testing)
str(my_training)
plot(modFitB1)
View(myTraining[2,-58])
View(my_training[2,-58])
str(my_training[2,-58])
# To get the same class between testing and myTraining
pml_testing <- rbind(my_training[2, -58] , pml_testing)
pml_testing <- pml_testing[-1,]
str(pml_testing)
predictionB2 <- predict(modFitB1, pml_testing, type = "class")
predictionB2
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
str(pml_testing_url)
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#rad
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
#set library path
.libPaths("D:/R/R-3.5.0/library")
View(pml_testing)
View(pml_training)
colnames(pml_testing)==colnames(pml_training)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
#set library path
.libPaths("D:/R/R-3.5.0/library")
#Load Packages
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training); dim(my_testing)
rm(inTrain)
#Remove predictors with unique value or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv <- nearZeroVar(my_training, saveMetrics=TRUE)
nzv
#Remove predictors with unique value or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv <- nearZeroVar(my_training)
nzv
length(nzv)
nzv <- nearZeroVar(my_training, saveMetrics=TRUE)
my_training <- my_training[,nzv$nzv==FALSE]
nzv
#Remove predictors with unique value or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv <- nearZeroVar(my_training)
my_training <- my_training[,nzv]
nzv
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training);
dim(my_testing)
rm(inTrain)
# Remove the extra first column; equivalent to row names.
my_training <- my_training[c(-1)]
#Remove predictors with unique value or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv <- nearZeroVar(my_training)
my_training <- my_training[,nzv]
nzv<- nearZeroVar(my_testing,saveMetrics=TRUE)
my_testing <- my_testing[,nzv$nzv==FALSE]
rm(nzv)
# Clean variables with more than 70% NA
index_to_rm <- NULL
for (i in 1:ncol(my_training))
{
if  ( length(which(is.na(my_training[,i])==T)) / nrow(my_training) >= 0.7 )
index_to_rm <- append(index_to_rm, i)
}
my_training <- my_training[,-index_to_rm]
rm(i, index_to_rm)
# Clean pml_testing & my_testing data frames based on the below cleaning.
clean1 <- colnames(my_training)
clean2 <- colnames(my_training[, -58])  # remove the classe column
#set library path
.libPaths("D:/R/R-3.5.0/library")
#Load Packages
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training);
dim(my_testing)
rm(inTrain)
my_training <- my_training[c(-1)]
#Remove predictors with unique value or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv <- nearZeroVar(my_training)
my_training <- my_training[,nzv]
nzv<- nearZeroVar(my_testing,saveMetrics=TRUE)
my_testing <- my_testing[,nzv$nzv==FALSE]
rm(nzv)
# Clean variables with more than 70% NA
index_to_rm <- NULL
for (i in 1:ncol(my_training))
{
if  ( length(which(is.na(my_training[,i])==T)) / nrow(my_training) >= 0.7 )
index_to_rm <- append(index_to_rm, i)
}
my_training <- my_training[,-index_to_rm]
rm(i, index_to_rm)
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training);
dim(my_testing)
rm(inTrain)
# Remove the extra first column; equivalent to row names.
my_training <- my_training[c(-1)]
#Remove predictors that have one unique value (i.e: zero variance predictors) or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv_vector <- nearZeroVar(my_training, saveMetrics=TRUE)
my_training <- my_training[,nzv_vector$nzv_vector==FALSE]
nzv_vector<- nearZeroVar(my_testing,saveMetrics=TRUE)
my_testing <- my_testing[,nzv_vector$nzv_vector==FALSE]
rm(nzv_vector)
# Clean variables with more than 70% NA
index_to_rm <- NULL
for (i in 1:ncol(my_training))
{
if  ( length(which(is.na(my_training[,i])==T)) / nrow(my_training) >= 0.7 )
index_to_rm <- append(index_to_rm, i)
}
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training);
dim(my_testing)
rm(inTrain)
nzv_vector <- nearZeroVar(my_training, saveMetrics=TRUE)
my_training <- my_training[,nzv_vector$nzv_vector==FALSE]
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training);
dim(my_testing)
rm(inTrain)
# Remove the extra first column; equivalent to row names.
my_training <- my_training[c(-1)]
#Remove predictors that have one unique value (i.e: zero variance predictors) or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv <- nearZeroVar(my_training, saveMetrics=TRUE)
nzv
my_training <- my_training[,nzv$nzv==FALSE]
nzv_vector<- nearZeroVar(my_testing,saveMetrics=TRUE)
my_testing <- my_testing[,nzv_vector$nzv_vector==FALSE]
#set library path
.libPaths("D:/R/R-3.5.0/library")
#Load Packages
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training);
dim(my_testing)
rm(inTrain)
# Remove the extra first column; equivalent to row names.
my_training <- my_training[c(-1)]
#Remove predictors that have one unique value (i.e: zero variance predictors) or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv_vector <- nearZeroVar(my_training, saveMetrics=TRUE)
my_training <- my_training[,nzv_vector$nzv_vector==FALSE]
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training);
dim(my_testing)
rm(inTrain)
# Remove the extra first column; equivalent to row names.
my_training <- my_training[c(-1)]
nzv <- nearZeroVar(my_training, saveMetrics=TRUE)
my_training <- my_training[,nzv$nzv==FALSE]
nzv<- nearZeroVar(my_testing,saveMetrics=TRUE)
my_testing <- my_testing[,nzv$nzv==FALSE]
# Clean variables with more than 70% NA
index_to_rm <- NULL
for (i in 1:ncol(my_training))
{
if  ( length(which(is.na(my_training[,i])==T)) / nrow(my_training) >= 0.7 )
index_to_rm <- append(index_to_rm, i)
}
my_training <- my_training[,-index_to_rm]
rm(i, index_to_rm,nzv_vector)
# Specify which columns to include in each of pml_testing & my_testing data frames for consistency with my_training.
columns_to_include_in_mytesting <- colnames(my_training)          # we will classe variable to build the confusion matrix (together with our prediction)
columns_to_include_in_pmltesting <- colnames(my_training[, -58])  # since the classe variable doesn't exist in pml_testing
my_testing <- my_testing[columns_to_include_in_mytesting]         # allow only variables in mytesting that are also in mytraining (this includes classe variable)
pml_testing <- pml_testing[columns_to_include_in_pmltesting]     # allow only variables in pml_testing that are also in mytraining (this doesn't include classe variable)
rm(clean1,clean2)
rm(columns_to_include_in_mytesting,columns_to_include_in_pmltesting)
#  print the dimensions of my_testing and pml_testing
dim(my_testing)
dim(pml_testing)
my_training[,c(5:(length(my_training)-1))] <- apply(my_training[,c(5:(length(my_training)-1))], 2, function(x) as.numeric(x))
my_testing[,c(5:(length(my_testing)-1))] <- apply(my_testing[,c(5:(length(my_testing)-1))], 2, function(x) as.numeric(x))
my_testing[,c(5:length(pml_testing))] <- apply(pml_testing[,c(5:length(pml_testing))], 2, function(x) as.numeric(x))
pml_testing[,c(5:length(pml_testing))] <- apply(pml_testing[,c(5:length(pml_testing))], 2, function(x) as.numeric(x))
str(pml_testing)
str(my_training)
#set library path
.libPaths("D:/R/R-3.5.0/library")
#Load Packages
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
inTrain <- createDataPartition(pml_training$classe, p=0.6, list=FALSE) # 60% training and 40% testing
my_training <- pml_training[inTrain, ]
my_testing <- pml_training[-inTrain, ]
dim(my_training);
dim(my_testing)
rm(inTrain)
# Remove the extra first column; equivalent to row names.
my_training <- my_training[c(-1)]
#Remove predictors that have one unique value (i.e: zero variance predictors) or those that satisfy the following:
#1. Very few unique values relative to the number of samples
#2. Ratio of the frequency of the most common value to the frequency of the second most common value is large
nzv <- nearZeroVar(my_training, saveMetrics=TRUE)
my_training <- my_training[,nzv$nzv==FALSE]
nzv<- nearZeroVar(my_testing,saveMetrics=TRUE)
my_testing <- my_testing[,nzv$nzv==FALSE]
# Clean variables with more than 70% NA
index_to_rm <- NULL
for (i in 1:ncol(my_training))
{
if  ( length(which(is.na(my_training[,i])==T)) / nrow(my_training) >= 0.7 )
index_to_rm <- append(index_to_rm, i)
}
my_training <- my_training[,-index_to_rm]
rm(i, index_to_rm,nzv_vector)
# Specify which columns to include in each of pml_testing & my_testing data frames for consistency with my_training.
columns_to_include_in_mytesting <- colnames(my_training)          # we will classe variable to build the confusion matrix (together with our prediction)
columns_to_include_in_pmltesting <- colnames(my_training[, -58])  # since the classe variable doesn't exist in pml_testing
my_testing <- my_testing[columns_to_include_in_mytesting]         # allow only variables in mytesting that are also in mytraining (this includes classe variable)
pml_testing <- pml_testing[columns_to_include_in_pmltesting]      # allow only variables in pml_testing that are also in mytraining (this doesn't include classe variable)
rm(columns_to_include_in_mytesting,columns_to_include_in_pmltesting)
#  print the dimensions of my_testing and pml_testing
dim(my_testing)
dim(pml_testing)
#  Unifying data structures between my_training, my_testing and pml_testing by converting all integer variable types into numerics (for the commonly existing columns)
# To get the same class between testing and mytraining
my_testing <- rbind(my_training[2, ] , my_testing)
my_testing <- my_testing[-1,]
# To get the same class between testing and mytraining
pml_testing <- rbind(my_training[2, -58] , pml_testing)
pml_testing <- pml_testing[-1,]
set.seed(1)
modFitA1 <- rpart(classe ~ ., data=my_training, method="class") #use all variables to predict the classe outcome.
fancyRpartPlot(modFitA1)
predictionsA1 <- predict(modFitA1, my_testing, type = "class") #apply model on my_testing
cmtree <- confusionMatrix(predictionsA1, my_testing$classe)    #insepect accuracy and other statistics via confusionMatrix by comparing with the original my_testing data
cmtree
plot(cmtree$table, col = cmtree$byClass, main = paste("Decision Tree Confusion Matrix: Accuracy =", round(cmtree$overall['Accuracy'], 3)))
set.seed(1)
modFitB1 <- randomForest(classe ~ ., data=my_training)
predictionB1 <- predict(modFitB1, my_testing, type = "class")
cmrf <- confusionMatrix(predictionB1, my_testing$classe)
cmrf
predictionB2 <- predict(modFitB1, pml_testing, type = "class")
predictionB2
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
#set library path
.libPaths("D:/R/R-3.5.0/library")
#Load Packages
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
#LOAD DATA
pml_training_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_testing_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read data and replace the empty/non existing cells with NA
pml_training <- read.csv(url(pml_training_url), na.strings=c("NA","#DIV/0!",""))
pml_testing <- read.csv(url(pml_testing_url), na.strings=c("NA","#DIV/0!",""))
rm(pml_training_url,pml_testing_url)
100-99.95
#  print the dimensions of my_testing and pml_testing
paste("dim of my_testing :", dim(my_testing))
